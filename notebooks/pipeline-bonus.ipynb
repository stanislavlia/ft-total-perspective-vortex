{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037dd191-82c4-401f-9594-a7aeb2307ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1d162b-924b-4478-8a88-cb5adea20add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============SETTINGS============\n",
    "RAW_DATA_DIR = \"../data/raw\"\n",
    "TASK_PARAGIDM=\"left_right_hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398e546-aa24-4e32-b6c3-8c6898238d6c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd4390f-4957-49bc-a375-e861e4cc50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Type to Task Map\n",
    "run_type_to_task = {\n",
    "    \"R01\": {\n",
    "        \"name\": \"Baseline - Eyes Open\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R02\": {\n",
    "        \"name\": \"Baseline - Eyes Closed\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R03\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R04\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R05\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R06\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R07\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R08\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R09\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R10\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R11\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R12\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R13\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R14\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "MOTOR_CHANNELS = [\n",
    "    'C3..',   # Left motor cortex (primary)\n",
    "    'Cz..',   # Central motor area (feet)\n",
    "    'C4..',   # Right motor cortex (primary)\n",
    "    'Fc3.',   # Left frontal-central (premotor)\n",
    "    'Fc4.',   # Right frontal-central (premotor)\n",
    "    'Cp3.',   # Left central-parietal (sensorimotor)\n",
    "    'Cp4.',   # Right central-parietal (sensorimotor)\n",
    "    'C5..',   # Left lateral motor\n",
    "    'C1..',   # Left medial motor\n",
    "    'C2..',   # Right medial motor\n",
    "    'C6..',   # Right lateral motor\n",
    "    'Fc1.',   # Left medial frontal-central\n",
    "    'Fc2.',   # Right medial frontal-central\n",
    "    'Fc5.',   # Left lateral frontal-central\n",
    "    'Fc6.',   # Right lateral frontal-central\n",
    "    'Cp1.',   # Left medial central-parietal\n",
    "    'Cp2.',   # Right medial central-parietal\n",
    "    'Cp5.',   # Left lateral central-parietal\n",
    "    'Cp6.'    # Right lateral central-parietal\n",
    "]\n",
    "\n",
    "extract_task_id = lambda filepath: 'R' + filepath.split('R')[-1].split('.')[0]\n",
    "\n",
    "def rename_annotations(raw, run_type):\n",
    "    \"\"\"\n",
    "    Rename MNE annotations to readable task labels\n",
    "    \"\"\"\n",
    "    task_info = run_type_to_task[run_type]\n",
    "    \n",
    "    if task_info['labels'] is not None:\n",
    "        # Map T0, T1, T2 to readable names\n",
    "        annotation_mapping = {\n",
    "            'T0': 'rest',\n",
    "            'T1': task_info['labels']['T1'],\n",
    "            'T2': task_info['labels']['T2']\n",
    "        }\n",
    "        \n",
    "        raw.annotations.rename(annotation_mapping)\n",
    "    \n",
    "    # Extract events with new names\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    return event_dict\n",
    "\n",
    "def select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type=\"motor_imagery\"):\n",
    "    \"\"\"\n",
    "    Select motor imagery EEG files for a subject by paradigm\n",
    "    \"\"\"\n",
    "    matching_runs = [\n",
    "        run_id for run_id, info in run_type_to_task.items()\n",
    "        if info.get('paradigm') == paradigm and info['task_type'] == task_type\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        os.path.join(RAW_DATA_DIR, subject_id, f\"{subject_id}{run_id}.edf\")\n",
    "        for run_id in sorted(matching_runs)\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_and_concatenate_to_epochs(files, tmin=-0.5, tmax=3.5, picks=MOTOR_CHANNELS):\n",
    "    \"\"\"\n",
    "    Load multiple EDF files and concatenate into single Epochs object\n",
    "    \"\"\"\n",
    "    epochs_list = []\n",
    "    \n",
    "    for filepath in files:\n",
    "        # Extract run_id\n",
    "        run_id = extract_task_id(filepath)\n",
    "        \n",
    "        # Load raw\n",
    "        raw = mne.io.read_raw_edf(filepath, preload=True, verbose=False)\n",
    "        \n",
    "        # Rename annotations\n",
    "        event_dict = rename_annotations(raw, run_id)\n",
    "        \n",
    "        # Get events (exclude rest)\n",
    "        events, _ = mne.events_from_annotations(raw)\n",
    "        event_id = {k: v for k, v in event_dict.items() if k != 'rest'}\n",
    "        \n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(\n",
    "            raw, events, event_id=event_id,\n",
    "            tmin=tmin, tmax=tmax,\n",
    "            baseline=None,\n",
    "            picks=picks,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        epochs_list.append(epochs)\n",
    "    \n",
    "    # Concatenate\n",
    "    return mne.concatenate_epochs(epochs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b06b6a-0f73-40fc-8a4f-c73fe4b930ba",
   "metadata": {},
   "source": [
    "# Classification Pipeline + Wavelets (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873a25d-5c2c-45cd-9fee-e8149a61fb55",
   "metadata": {},
   "source": [
    "## Haar Wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f89a6b7-fafb-4a39-a662-c62f3a80cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar_dwt_forward(signal):\n",
    "    \"\"\"One-level DWT - vectorized\"\"\"\n",
    "    N = len(signal)\n",
    "    if N % 2:\n",
    "        signal = np.append(signal, signal[-1])\n",
    "        N = len(signal)\n",
    "    \n",
    "    # Reshape to pairs: (N//2, 2)\n",
    "    pairs = signal.reshape(N//2, 2)\n",
    "    \n",
    "    # Vectorized operations\n",
    "    approx = (pairs[:, 0] + pairs[:, 1]) / np.sqrt(2)\n",
    "    detail = (pairs[:, 0] - pairs[:, 1]) / np.sqrt(2)\n",
    "    \n",
    "    return approx, detail\n",
    "\n",
    "def haar_dwt_multilevel(signal, n_levels=5):\n",
    "    \"\"\"\n",
    "    Multi-level Haar DWT - vectorized.\n",
    "    \n",
    "    Returns: [approximation, detail_n, detail_n-1, ..., detail_1]\n",
    "    \"\"\"\n",
    "    coeffs = []\n",
    "    current = signal.copy()\n",
    "    \n",
    "    for _ in range(n_levels):\n",
    "        if len(current) < 2:\n",
    "            break\n",
    "        approx, detail = haar_dwt_forward(current)\n",
    "        coeffs.append(detail)\n",
    "        current = approx\n",
    "    \n",
    "    coeffs.append(current)\n",
    "    return coeffs[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753c0b02-f795-4d0f-8aaf-adf70e169080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class HaarWaveletTransform(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Apply Haar to each channel, keep 3D shape for CSP.\"\"\"\n",
    "    def __init__(self, n_levels=4):\n",
    "        self.n_levels = n_levels\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: (n_trials, n_channels, n_times)\n",
    "        Returns: (n_trials, n_channels, n_wavelet_coeffs)\n",
    "        \"\"\"\n",
    "        n_trials, n_channels, n_times = X.shape\n",
    "        \n",
    "        # Apply DWT to get coefficient length\n",
    "        sample_coeffs = haar_dwt_multilevel(X[0, 0, :], n_levels=self.n_levels)\n",
    "        n_coeffs = sum(len(c) for c in sample_coeffs)\n",
    "        \n",
    "        X_wavelet = np.zeros((n_trials, n_channels, n_coeffs))\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            for ch in range(n_channels):\n",
    "                coeffs = haar_dwt_multilevel(X[trial, ch, :], n_levels=self.n_levels)\n",
    "                # Flatten coefficients\n",
    "                X_wavelet[trial, ch, :] = np.concatenate(coeffs)\n",
    "        \n",
    "        # Replace any inf/nan\n",
    "        X_wavelet = np.nan_to_num(X_wavelet, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        \n",
    "        return X_wavelet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4f7c7-0c33-406c-a755-34ec966ea70a",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79c2bc65-051a-4bf5-b02b-e0acdad75222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "#HYPERPARAMS\n",
    "TEST_SIZE=0.20\n",
    "K_FOLDS=5\n",
    "N_COMPONENTS=6\n",
    "WAVELET_LEVEL=8\n",
    "RANDOM_STATE=42\n",
    "L_FREQ=8\n",
    "H_FREQ=30\n",
    "TMIN=0.5\n",
    "TMAX=3\n",
    "TASK_TYPE=\"motor_execution\"\n",
    "LIMIT=109\n",
    "\n",
    "def get_epochs_for_subject(subject_id, paradigm, task_type):\n",
    "    files = select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type)\n",
    "    epochs = load_and_concatenate_to_epochs(files, tmin=TMIN, tmax=TMAX, picks=MOTOR_CHANNELS)\n",
    "    epochs.filter(l_freq=L_FREQ, h_freq=H_FREQ, verbose=False) #Filter\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def get_pipeline_scores_for_subject(subject_id, paradigm, task_type):\n",
    "\n",
    "    epochs = get_epochs_for_subject(subject_id, paradigm, task_type)\n",
    "    \n",
    "    # Extract data and labels\n",
    "    X = epochs.get_data()  # (n_trials, n_channels, n_times)\n",
    "    y = epochs.events[:, -1]  # Labels (2 or 3 for left/right)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('wavelet', HaarWaveletTransform(n_levels=WAVELET_LEVEL)),\n",
    "        ('csp', CSP(n_components=N_COMPONENTS, reg=None, log=True)),\n",
    "        ('lda', LinearDiscriminantAnalysis())\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=K_FOLDS)\n",
    "    \n",
    "    # Train on full training set and evaluate on test set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    return {\n",
    "        'cv_score': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_score': test_score\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "subject_ids = [f\"S{i:03d}\" for i in range(1, 110)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "569461e5-f510-482a-aa5e-3b812c9ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline_on_experiment(task_paradigm, task_type):\n",
    "    \n",
    "    subject_results = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(LIMIT)):\n",
    "        results = get_pipeline_scores_for_subject(subject_ids[i], task_paradigm, task_type)\n",
    "        subject_results.append(results)\n",
    "\n",
    "    \n",
    "    results_df = pd.DataFrame(subject_results)\n",
    "    return {\n",
    "        \"task_paradigm\" : task_paradigm,\n",
    "        \"task_type\" : task_type,\n",
    "        \"cv_score\" : float(results_df.mean()[\"cv_score\"]),\n",
    "        \"test_score\" : float(results_df.mean()[\"test_score\"])\n",
    "    }\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a05662-8658-4f39-a125-f1ede085d8d7",
   "metadata": {},
   "source": [
    "## Evaluate on all experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f474aa9c-a31b-4cf6-8676-680a5c4f6d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 109/109 [01:47<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 0: accuracy = 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 109/109 [01:47<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1: accuracy = 0.6365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 109/109 [01:49<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 2: accuracy = 0.7871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 109/109 [01:51<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 3: accuracy = 0.6618\n",
      "\n",
      "Mean accuracy of 4 experiments: 0.6848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run 4 experiments - print each as it completes\n",
    "experiments = []\n",
    "\n",
    "exp0 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_execution')\n",
    "print(f\"experiment 0: accuracy = {exp0['test_score']:.4f}\")\n",
    "experiments.append(exp0)\n",
    "\n",
    "exp1 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_imagery')\n",
    "print(f\"experiment 1: accuracy = {exp1['test_score']:.4f}\")\n",
    "experiments.append(exp1)\n",
    "\n",
    "exp2 = evaluate_pipeline_on_experiment('hands_feet', 'motor_execution')\n",
    "print(f\"experiment 2: accuracy = {exp2['test_score']:.4f}\")\n",
    "experiments.append(exp2)\n",
    "\n",
    "exp3 = evaluate_pipeline_on_experiment('hands_feet', 'motor_imagery')\n",
    "print(f\"experiment 3: accuracy = {exp3['test_score']:.4f}\")\n",
    "experiments.append(exp3)\n",
    "\n",
    "# Final mean\n",
    "mean_accuracy = sum(e['test_score'] for e in experiments) / 4\n",
    "print(f\"\\nMean accuracy of 4 experiments: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda61193-43be-41bc-98a6-7199b101b0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd314de-275b-4d6e-9278-47f4f00948e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
