{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037dd191-82c4-401f-9594-a7aeb2307ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1d162b-924b-4478-8a88-cb5adea20add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============SETTINGS============\n",
    "RAW_DATA_DIR = \"../data/raw\"\n",
    "TASK_PARAGIDM=\"left_right_hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398e546-aa24-4e32-b6c3-8c6898238d6c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd4390f-4957-49bc-a375-e861e4cc50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Type to Task Map\n",
    "run_type_to_task = {\n",
    "    \"R01\": {\n",
    "        \"name\": \"Baseline - Eyes Open\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R02\": {\n",
    "        \"name\": \"Baseline - Eyes Closed\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R03\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R04\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R05\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R06\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R07\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R08\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R09\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R10\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R11\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R12\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R13\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R14\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "MOTOR_CHANNELS = [\n",
    "    'C3..',   # Left motor cortex (primary)\n",
    "    'Cz..',   # Central motor area (feet)\n",
    "    'C4..',   # Right motor cortex (primary)\n",
    "    'Fc3.',   # Left frontal-central (premotor)\n",
    "    'Fc4.',   # Right frontal-central (premotor)\n",
    "    'Cp3.',   # Left central-parietal (sensorimotor)\n",
    "    'Cp4.',   # Right central-parietal (sensorimotor)\n",
    "    'C5..',   # Left lateral motor\n",
    "    'C1..',   # Left medial motor\n",
    "    'C2..',   # Right medial motor\n",
    "    'C6..',   # Right lateral motor\n",
    "    'Fc1.',   # Left medial frontal-central\n",
    "    'Fc2.',   # Right medial frontal-central\n",
    "    'Fc5.',   # Left lateral frontal-central\n",
    "    'Fc6.',   # Right lateral frontal-central\n",
    "    'Cp1.',   # Left medial central-parietal\n",
    "    'Cp2.',   # Right medial central-parietal\n",
    "    'Cp5.',   # Left lateral central-parietal\n",
    "    'Cp6.'    # Right lateral central-parietal\n",
    "]\n",
    "\n",
    "extract_task_id = lambda filepath: 'R' + filepath.split('R')[-1].split('.')[0]\n",
    "\n",
    "def rename_annotations(raw, run_type):\n",
    "    \"\"\"\n",
    "    Rename MNE annotations to readable task labels\n",
    "    \"\"\"\n",
    "    task_info = run_type_to_task[run_type]\n",
    "    \n",
    "    if task_info['labels'] is not None:\n",
    "        # Map T0, T1, T2 to readable names\n",
    "        annotation_mapping = {\n",
    "            'T0': 'rest',\n",
    "            'T1': task_info['labels']['T1'],\n",
    "            'T2': task_info['labels']['T2']\n",
    "        }\n",
    "        \n",
    "        raw.annotations.rename(annotation_mapping)\n",
    "    \n",
    "    # Extract events with new names\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    return event_dict\n",
    "\n",
    "def select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type=\"motor_imagery\"):\n",
    "    \"\"\"\n",
    "    Select motor imagery EEG files for a subject by paradigm\n",
    "    \"\"\"\n",
    "    matching_runs = [\n",
    "        run_id for run_id, info in run_type_to_task.items()\n",
    "        if info.get('paradigm') == paradigm and info['task_type'] == task_type\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        os.path.join(RAW_DATA_DIR, subject_id, f\"{subject_id}{run_id}.edf\")\n",
    "        for run_id in sorted(matching_runs)\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_and_concatenate_to_epochs(files, tmin=-0.5, tmax=3.5, picks=MOTOR_CHANNELS):\n",
    "    \"\"\"\n",
    "    Load multiple EDF files and concatenate into single Epochs object\n",
    "    \"\"\"\n",
    "    epochs_list = []\n",
    "    \n",
    "    for filepath in files:\n",
    "        # Extract run_id\n",
    "        run_id = extract_task_id(filepath)\n",
    "        \n",
    "        # Load raw\n",
    "        raw = mne.io.read_raw_edf(filepath, preload=True, verbose=False)\n",
    "        \n",
    "        # Rename annotations\n",
    "        event_dict = rename_annotations(raw, run_id)\n",
    "        \n",
    "        # Get events (exclude rest)\n",
    "        events, _ = mne.events_from_annotations(raw)\n",
    "        event_id = {k: v for k, v in event_dict.items() if k != 'rest'}\n",
    "        \n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(\n",
    "            raw, events, event_id=event_id,\n",
    "            tmin=tmin, tmax=tmax,\n",
    "            baseline=None,\n",
    "            picks=picks,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        epochs_list.append(epochs)\n",
    "    \n",
    "    # Concatenate\n",
    "    return mne.concatenate_epochs(epochs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b06b6a-0f73-40fc-8a4f-c73fe4b930ba",
   "metadata": {},
   "source": [
    "# Classification Pipeline + Wavelets (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873a25d-5c2c-45cd-9fee-e8149a61fb55",
   "metadata": {},
   "source": [
    "## Haar Wavelets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f89a6b7-fafb-4a39-a662-c62f3a80cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haar_dwt_forward(signal):\n",
    "    \"\"\"One-level DWT - vectorized\"\"\"\n",
    "    N = len(signal)\n",
    "    if N % 2:\n",
    "        signal = np.append(signal, signal[-1])\n",
    "        N = len(signal)\n",
    "    \n",
    "    # Reshape to pairs: (N//2, 2)\n",
    "    pairs = signal.reshape(N//2, 2)\n",
    "    \n",
    "    # Vectorized operations\n",
    "    approx = (pairs[:, 0] + pairs[:, 1]) / np.sqrt(2)\n",
    "    detail = (pairs[:, 0] - pairs[:, 1]) / np.sqrt(2)\n",
    "    \n",
    "    return approx, detail\n",
    "\n",
    "def haar_dwt_multilevel(signal, n_levels=5):\n",
    "    \"\"\"\n",
    "    Multi-level Haar DWT - vectorized.\n",
    "    \n",
    "    Returns: [approximation, detail_n, detail_n-1, ..., detail_1]\n",
    "    \"\"\"\n",
    "    coeffs = []\n",
    "    current = signal.copy()\n",
    "    \n",
    "    for _ in range(n_levels):\n",
    "        if len(current) < 2:\n",
    "            break\n",
    "        approx, detail = haar_dwt_forward(current)\n",
    "        coeffs.append(detail)\n",
    "        current = approx\n",
    "    \n",
    "    coeffs.append(current)\n",
    "    return coeffs[::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753c0b02-f795-4d0f-8aaf-adf70e169080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class HaarWaveletTransform(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Apply Haar to each channel, keep 3D shape for CSP.\"\"\"\n",
    "    def __init__(self, n_levels=4):\n",
    "        self.n_levels = n_levels\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: (n_trials, n_channels, n_times)\n",
    "        Returns: (n_trials, n_channels, n_wavelet_coeffs)\n",
    "        \"\"\"\n",
    "        n_trials, n_channels, n_times = X.shape\n",
    "        \n",
    "        # Apply DWT to get coefficient length\n",
    "        sample_coeffs = haar_dwt_multilevel(X[0, 0, :], n_levels=self.n_levels)\n",
    "        n_coeffs = sum(len(c) for c in sample_coeffs)\n",
    "        \n",
    "        X_wavelet = np.zeros((n_trials, n_channels, n_coeffs))\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            for ch in range(n_channels):\n",
    "                coeffs = haar_dwt_multilevel(X[trial, ch, :], n_levels=self.n_levels)\n",
    "                # Flatten coefficients\n",
    "                X_wavelet[trial, ch, :] = np.concatenate(coeffs)\n",
    "        \n",
    "        # Replace any inf/nan\n",
    "        X_wavelet = np.nan_to_num(X_wavelet, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        \n",
    "        return X_wavelet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafa829-b522-43e8-9c90-3eaba09b0fad",
   "metadata": {},
   "source": [
    "### CSP Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34877201-1d6c-457b-a11c-b3517b7a3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "\n",
    "class CommonSpatialPattern(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_components):\n",
    "\n",
    "        if n_components % 2:\n",
    "            raise ValueError(f\"n_components should be even number! Got \" + n_components)\n",
    "\n",
    "        self.n_components  = n_components\n",
    "    \n",
    "    def _compute_average_covariance_matrix(self, X_class):\n",
    "        \"\"\"Compute average normalized covariance matrix for one class\"\"\"\n",
    "\n",
    "        n_trials, n_channels, n_times = X_class.shape\n",
    "\n",
    "        cov_sum = np.zeros((n_channels, n_channels))\n",
    "\n",
    "        for i in range(n_trials):\n",
    "            trial = X_class[i]\n",
    "\n",
    "            #computes covariance matrix\n",
    "            cov = np.cov(trial)\n",
    "\n",
    "            #normalize by trace (sum of diagonal elements)\n",
    "            cov = cov / np.trace(cov)\n",
    "            cov_sum += cov\n",
    "        \n",
    "        cov_avg = cov_sum / n_trials\n",
    "        return cov_avg\n",
    "\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        #check only 2 classes present\n",
    "        classes = np.unique(y)\n",
    "        assert len(classes) == 2\n",
    "\n",
    "        X_class0 = X[y == classes[0]]\n",
    "        X_class1 = X[y == classes[1]]\n",
    "\n",
    "        #compute Covariance matrices for both\n",
    "        cov0 = self._compute_average_covariance_matrix(X_class=X_class0)\n",
    "        cov1 = self._compute_average_covariance_matrix(X_class=X_class1)\n",
    "\n",
    "        # Solve generalized eigenvalue problem\n",
    "        # Find W such that: cov_class0 @ W = λ @ cov_class1 @ W\n",
    "        eigenvalues, eigenvectors = linalg.eigh(cov0, cov1)\n",
    "\n",
    "        #Now, we sort by eignenvalues in desc order\n",
    "        sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "        eigenvalues = eigenvalues[sorted_idx]\n",
    "        eigenvectors = eigenvectors[:, sorted_idx]\n",
    "\n",
    "        # Now, components at the begining of list are such that var for class0 is minimized while var for class1 is maximized.\n",
    "        # At the end of list, we have the opposite.\n",
    "        # We need to select  n_components/2 from top and bottom\n",
    "\n",
    "        selected_components = np.concatenate(\n",
    "            [\n",
    "            eigenvectors[:, :self.n_components // 2], #top\n",
    "            eigenvectors[:, - self.n_components // 2:], #bottom\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        self.filters_ = selected_components # (n_channels, n_components)\n",
    "        self.patterns_ = linalg.pinv(self.filters_.T) #inverse for interpretation\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Applies learnt CSP filters and transform trial from (n_channels, n_times) to (n_components,)\"\"\"\n",
    "\n",
    "        n_trials = X.shape[0]\n",
    "\n",
    "        if self.filters_ is None:\n",
    "            raise ValueError(\"Must call fit() before transform()!\")\n",
    "\n",
    "        X_transformed = np.zeros((n_trials, self.n_components))\n",
    "\n",
    "        \n",
    "        for i in range(n_trials):\n",
    "\n",
    "            filtered = self.filters_.T @ X[i] #produces (n_components, n_times) shape\n",
    "\n",
    "            #collapse time dimension by computing variance\n",
    "            features = np.log(np.var(filtered, axis=1))\n",
    "            X_transformed[i, :] = features\n",
    "            \n",
    "\n",
    "        return X_transformed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4f7c7-0c33-406c-a755-34ec966ea70a",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c2bc65-051a-4bf5-b02b-e0acdad75222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "#HYPERPARAMS\n",
    "TEST_SIZE=0.20\n",
    "K_FOLDS=5\n",
    "N_COMPONENTS=6\n",
    "WAVELET_LEVEL=8\n",
    "RANDOM_STATE=42\n",
    "L_FREQ=8\n",
    "H_FREQ=30\n",
    "TMIN=0.5\n",
    "TMAX=3\n",
    "TASK_TYPE=\"motor_execution\"\n",
    "LIMIT=109\n",
    "\n",
    "def get_epochs_for_subject(subject_id, paradigm, task_type):\n",
    "    files = select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type)\n",
    "    epochs = load_and_concatenate_to_epochs(files, tmin=TMIN, tmax=TMAX, picks=MOTOR_CHANNELS)\n",
    "    epochs.filter(l_freq=L_FREQ, h_freq=H_FREQ, verbose=False) #Filter\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def get_pipeline_scores_for_subject(subject_id, paradigm, task_type):\n",
    "\n",
    "    epochs = get_epochs_for_subject(subject_id, paradigm, task_type)\n",
    "    \n",
    "    # Extract data and labels\n",
    "    X = epochs.get_data()  # (n_trials, n_channels, n_times)\n",
    "    y = epochs.events[:, -1]  # Labels (2 or 3 for left/right)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('wavelet', HaarWaveletTransform(n_levels=WAVELET_LEVEL)),\n",
    "        ('csp', CommonSpatialPattern(n_components=N_COMPONENTS)),\n",
    "        #('csp', CSP(n_components=N_COMPONENTS, reg=None, log=True)),\n",
    "        ('lda', LinearDiscriminantAnalysis())\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=K_FOLDS)\n",
    "    \n",
    "    # Train on full training set and evaluate on test set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    return {\n",
    "        'cv_score': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_score': test_score\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "subject_ids = [f\"S{i:03d}\" for i in range(1, 110)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569461e5-f510-482a-aa5e-3b812c9ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline_on_experiment(task_paradigm, task_type):\n",
    "    \n",
    "    subject_results = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(LIMIT)):\n",
    "        results = get_pipeline_scores_for_subject(subject_ids[i], task_paradigm, task_type)\n",
    "        subject_results.append(results)\n",
    "\n",
    "    \n",
    "    results_df = pd.DataFrame(subject_results)\n",
    "    return {\n",
    "        \"task_paradigm\" : task_paradigm,\n",
    "        \"task_type\" : task_type,\n",
    "        \"cv_score\" : float(results_df.mean()[\"cv_score\"]),\n",
    "        \"test_score\" : float(results_df.mean()[\"test_score\"])\n",
    "    }\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a05662-8658-4f39-a125-f1ede085d8d7",
   "metadata": {},
   "source": [
    "## Evaluate on all experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f474aa9c-a31b-4cf6-8676-680a5c4f6d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                    | 14/109 [00:04<00:27,  3.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run 4 experiments - print each as it completes\u001b[39;00m\n\u001b[32m      2\u001b[39m experiments = []\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m exp0 = \u001b[43mevaluate_pipeline_on_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mleft_right_hand\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmotor_execution\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexperiment 0: accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp0[\u001b[33m'\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m experiments.append(exp0)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mevaluate_pipeline_on_experiment\u001b[39m\u001b[34m(task_paradigm, task_type)\u001b[39m\n\u001b[32m      3\u001b[39m subject_results = []\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(LIMIT)):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     results = \u001b[43mget_pipeline_scores_for_subject\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_paradigm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     subject_results.append(results)\n\u001b[32m     11\u001b[39m results_df = pd.DataFrame(subject_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mget_pipeline_scores_for_subject\u001b[39m\u001b[34m(subject_id, paradigm, task_type)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_pipeline_scores_for_subject\u001b[39m(subject_id, paradigm, task_type):\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     epochs = \u001b[43mget_epochs_for_subject\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparadigm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Extract data and labels\u001b[39;00m\n\u001b[32m     34\u001b[39m     X = epochs.get_data()  \u001b[38;5;66;03m# (n_trials, n_channels, n_times)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mget_epochs_for_subject\u001b[39m\u001b[34m(subject_id, paradigm, task_type)\u001b[39m\n\u001b[32m     23\u001b[39m files = select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type)\n\u001b[32m     24\u001b[39m epochs = load_and_concatenate_to_epochs(files, tmin=TMIN, tmax=TMAX, picks=MOTOR_CHANNELS)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mepochs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mL_FREQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mH_FREQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Filter\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m epochs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-58>:10\u001b[39m, in \u001b[36mfilter\u001b[39m\u001b[34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/filter.py:2558\u001b[39m, in \u001b[36mFilterMixin.filter\u001b[39m\u001b[34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[39m\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m si, (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(onsets, ends)):\n\u001b[32m   2555\u001b[39m     \u001b[38;5;66;03m# Only output filter params once (for info level), and only warn\u001b[39;00m\n\u001b[32m   2556\u001b[39m     \u001b[38;5;66;03m# once about the length criterion (longest segment is too short)\u001b[39;00m\n\u001b[32m   2557\u001b[39m     use_verbose = verbose \u001b[38;5;28;01mif\u001b[39;00m si == max_idx \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2558\u001b[39m     \u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2559\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2560\u001b[39m \u001b[43m        \u001b[49m\u001b[43ms_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2561\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m        \u001b[49m\u001b[43mh_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2573\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2576\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2577\u001b[39m \u001b[38;5;66;03m# update info if filter is applied to all data channels/vertices,\u001b[39;00m\n\u001b[32m   2578\u001b[39m \u001b[38;5;66;03m# and it's not a band-stop filter\u001b[39;00m\n\u001b[32m   2579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, _BaseSourceEstimate):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-53>:10\u001b[39m, in \u001b[36mfilter_data\u001b[39m\u001b[34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/filter.py:1031\u001b[39m, in \u001b[36mfilter_data\u001b[39m\u001b[34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[39m\n\u001b[32m   1016\u001b[39m filt = create_filter(\n\u001b[32m   1017\u001b[39m     data,\n\u001b[32m   1018\u001b[39m     sfreq,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1028\u001b[39m     fir_design,\n\u001b[32m   1029\u001b[39m )\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mfir\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfft\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     data = \u001b[43m_overlap_add_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1033\u001b[39m     data = _iir_filter(data, filt, picks, n_jobs, copy, phase)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/filter.py:346\u001b[39m, in \u001b[36m_overlap_add_filter\u001b[39m\u001b[34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[39m\n\u001b[32m    342\u001b[39m         x[p] = _1d_overlap_filter(\n\u001b[32m    343\u001b[39m             x[p], \u001b[38;5;28mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[32m    344\u001b[39m         )\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     data_new = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pp, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(picks):\n\u001b[32m    350\u001b[39m         x[p] = data_new[pp]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/filter.py:347\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    342\u001b[39m         x[p] = _1d_overlap_filter(\n\u001b[32m    343\u001b[39m             x[p], \u001b[38;5;28mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[32m    344\u001b[39m         )\n\u001b[32m    345\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    346\u001b[39m     data_new = parallel(\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         \u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m picks\n\u001b[32m    348\u001b[39m     )\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pp, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(picks):\n\u001b[32m    350\u001b[39m         x[p] = data_new[pp]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/filter.py:375\u001b[39m, in \u001b[36m_1d_overlap_filter\u001b[39m\u001b[34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[39m\n\u001b[32m    372\u001b[39m seg = x_ext[start:stop]\n\u001b[32m    373\u001b[39m seg = np.concatenate([seg, np.zeros(n_fft - \u001b[38;5;28mlen\u001b[39m(seg))])\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m prod = \u001b[43m_fft_multiply_repeated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m start_filt = \u001b[38;5;28mmax\u001b[39m(\u001b[32m0\u001b[39m, start - shift)\n\u001b[32m    378\u001b[39m stop_filt = \u001b[38;5;28mmin\u001b[39m(start - shift + n_fft, n_x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/cuda.py:215\u001b[39m, in \u001b[36m_fft_multiply_repeated\u001b[39m\u001b[34m(x, cuda_dict)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Do FFT multiplication by a filter function (possibly using CUDA).\u001b[39;00m\n\u001b[32m    197\u001b[39m \n\u001b[32m    198\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m \u001b[33;03m    Filtered version of x.\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[38;5;66;03m# do the fourier-domain operations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m x_fft = \u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrfft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_fft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m x_fft *= cuda_dict[\u001b[33m\"\u001b[39m\u001b[33mh_fft\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    217\u001b[39m x = cuda_dict[\u001b[33m\"\u001b[39m\u001b[33mirfft\u001b[39m\u001b[33m\"\u001b[39m](x_fft, cuda_dict[\u001b[33m\"\u001b[39m\u001b[33mn_fft\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/scipy/fft/_backend.py:29\u001b[39m, in \u001b[36m_ScipyBackend.__ua_function__\u001b[39m\u001b[34m(method, args, kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:91\u001b[39m, in \u001b[36mrfft\u001b[39m\u001b[34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrfft\u001b[39m(x, n=\u001b[38;5;28;01mNone\u001b[39;00m, axis=-\u001b[32m1\u001b[39m, norm=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     90\u001b[39m          overwrite_x=\u001b[38;5;28;01mFalse\u001b[39;00m, workers=\u001b[38;5;28;01mNone\u001b[39;00m, *, plan=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_1D\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrfft\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/scipy/fft/_basic_backend.py:32\u001b[39m, in \u001b[36m_execute_1D\u001b[39m\u001b[34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[32m     31\u001b[39m     x = np.asarray(x)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m norm = _validate_fft_args(workers, plan, norm)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[33m'\u001b[39m\u001b[33mfft\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/scipy/fft/_pocketfft/basic.py:61\u001b[39m, in \u001b[36mr2c\u001b[39m\u001b[34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minvalid number of data points (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtmp.shape[axis]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Note: overwrite_x is not utilised\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mr2c\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run 4 experiments - print each as it completes\n",
    "experiments = []\n",
    "\n",
    "exp0 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_execution')\n",
    "print(f\"experiment 0: accuracy = {exp0['test_score']:.4f}\")\n",
    "experiments.append(exp0)\n",
    "\n",
    "exp1 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_imagery')\n",
    "print(f\"experiment 1: accuracy = {exp1['test_score']:.4f}\")\n",
    "experiments.append(exp1)\n",
    "\n",
    "exp2 = evaluate_pipeline_on_experiment('hands_feet', 'motor_execution')\n",
    "print(f\"experiment 2: accuracy = {exp2['test_score']:.4f}\")\n",
    "experiments.append(exp2)\n",
    "\n",
    "exp3 = evaluate_pipeline_on_experiment('hands_feet', 'motor_imagery')\n",
    "print(f\"experiment 3: accuracy = {exp3['test_score']:.4f}\")\n",
    "experiments.append(exp3)\n",
    "\n",
    "# Final mean\n",
    "mean_accuracy = sum(e['test_score'] for e in experiments) / 4\n",
    "print(f\"\\nMean accuracy of 4 experiments: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda61193-43be-41bc-98a6-7199b101b0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd314de-275b-4d6e-9278-47f4f00948e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
