{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037dd191-82c4-401f-9594-a7aeb2307ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "from scipy.signal import welch\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1d162b-924b-4478-8a88-cb5adea20add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============SETTINGS============\n",
    "RAW_DATA_DIR = \"../data/raw\"\n",
    "TASK_PARAGIDM=\"left_right_hand\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398e546-aa24-4e32-b6c3-8c6898238d6c",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd4390f-4957-49bc-a375-e861e4cc50bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Type to Task Map\n",
    "run_type_to_task = {\n",
    "    \"R01\": {\n",
    "        \"name\": \"Baseline - Eyes Open\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R02\": {\n",
    "        \"name\": \"Baseline - Eyes Closed\",\n",
    "        \"task_type\": \"baseline\",\n",
    "        \"labels\": None\n",
    "    },\n",
    "    \"R03\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R04\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R05\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R06\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R07\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R08\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R09\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R10\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R11\": {\n",
    "        \"name\": \"Task 1 - Real Left/Right Fist\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R12\": {\n",
    "        \"name\": \"Task 2 - Imagine Left/Right Fist\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"left_right_hand\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"left_fist\",\n",
    "            \"T2\": \"right_fist\"\n",
    "        }\n",
    "    },\n",
    "    \"R13\": {\n",
    "        \"name\": \"Task 3 - Real Fists/Feet\",\n",
    "        \"task_type\": \"motor_execution\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    },\n",
    "    \"R14\": {\n",
    "        \"name\": \"Task 4 - Imagine Fists/Feet\",\n",
    "        \"task_type\": \"motor_imagery\",\n",
    "        \"paradigm\": \"hands_feet\",\n",
    "        \"labels\": {\n",
    "            \"T1\": \"both_fists\",\n",
    "            \"T2\": \"both_feet\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "MOTOR_CHANNELS = [\n",
    "    'C3..',   # Left motor cortex (primary)\n",
    "    'Cz..',   # Central motor area (feet)\n",
    "    'C4..',   # Right motor cortex (primary)\n",
    "    'Fc3.',   # Left frontal-central (premotor)\n",
    "    'Fc4.',   # Right frontal-central (premotor)\n",
    "    'Cp3.',   # Left central-parietal (sensorimotor)\n",
    "    'Cp4.',   # Right central-parietal (sensorimotor)\n",
    "    'C5..',   # Left lateral motor\n",
    "    'C1..',   # Left medial motor\n",
    "    'C2..',   # Right medial motor\n",
    "    'C6..',   # Right lateral motor\n",
    "    'Fc1.',   # Left medial frontal-central\n",
    "    'Fc2.',   # Right medial frontal-central\n",
    "    'Fc5.',   # Left lateral frontal-central\n",
    "    'Fc6.',   # Right lateral frontal-central\n",
    "    'Cp1.',   # Left medial central-parietal\n",
    "    'Cp2.',   # Right medial central-parietal\n",
    "    'Cp5.',   # Left lateral central-parietal\n",
    "    'Cp6.'    # Right lateral central-parietal\n",
    "]\n",
    "\n",
    "extract_task_id = lambda filepath: 'R' + filepath.split('R')[-1].split('.')[0]\n",
    "\n",
    "def rename_annotations(raw, run_type):\n",
    "    \"\"\"\n",
    "    Rename MNE annotations to readable task labels\n",
    "    \"\"\"\n",
    "    task_info = run_type_to_task[run_type]\n",
    "    \n",
    "    if task_info['labels'] is not None:\n",
    "        # Map T0, T1, T2 to readable names\n",
    "        annotation_mapping = {\n",
    "            'T0': 'rest',\n",
    "            'T1': task_info['labels']['T1'],\n",
    "            'T2': task_info['labels']['T2']\n",
    "        }\n",
    "        \n",
    "        raw.annotations.rename(annotation_mapping)\n",
    "    \n",
    "    # Extract events with new names\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    return event_dict\n",
    "\n",
    "def select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type=\"motor_imagery\"):\n",
    "    \"\"\"\n",
    "    Select motor imagery EEG files for a subject by paradigm\n",
    "    \"\"\"\n",
    "    matching_runs = [\n",
    "        run_id for run_id, info in run_type_to_task.items()\n",
    "        if info.get('paradigm') == paradigm and info['task_type'] == task_type\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        os.path.join(RAW_DATA_DIR, subject_id, f\"{subject_id}{run_id}.edf\")\n",
    "        for run_id in sorted(matching_runs)\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_and_concatenate_to_epochs(files, tmin=-0.5, tmax=3.5, picks=MOTOR_CHANNELS):\n",
    "    \"\"\"\n",
    "    Load multiple EDF files and concatenate into single Epochs object\n",
    "    \"\"\"\n",
    "    epochs_list = []\n",
    "    \n",
    "    for filepath in files:\n",
    "        # Extract run_id\n",
    "        run_id = extract_task_id(filepath)\n",
    "        \n",
    "        # Load raw\n",
    "        raw = mne.io.read_raw_edf(filepath, preload=True, verbose=False)\n",
    "        \n",
    "        # Rename annotations\n",
    "        event_dict = rename_annotations(raw, run_id)\n",
    "        \n",
    "        # Get events (exclude rest)\n",
    "        events, _ = mne.events_from_annotations(raw)\n",
    "        event_id = {k: v for k, v in event_dict.items() if k != 'rest'}\n",
    "        \n",
    "        # Create epochs\n",
    "        epochs = mne.Epochs(\n",
    "            raw, events, event_id=event_id,\n",
    "            tmin=tmin, tmax=tmax,\n",
    "            baseline=None,\n",
    "            picks=picks,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        epochs_list.append(epochs)\n",
    "    \n",
    "    # Concatenate\n",
    "    return mne.concatenate_epochs(epochs_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b06b6a-0f73-40fc-8a4f-c73fe4b930ba",
   "metadata": {},
   "source": [
    "# Classification Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4f7c7-0c33-406c-a755-34ec966ea70a",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79c2bc65-051a-4bf5-b02b-e0acdad75222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mne.decoding import CSP\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from tqdm import tqdm\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "#HYPERPARAMS\n",
    "TEST_SIZE=0.20\n",
    "K_FOLDS=5\n",
    "N_COMPONENTS=6\n",
    "RANDOM_STATE=42\n",
    "L_FREQ=8\n",
    "H_FREQ=30\n",
    "TMIN=0.0\n",
    "TMAX=2.0\n",
    "TASK_TYPE=\"motor_execution\"\n",
    "\n",
    "def get_epochs_for_subject(subject_id, paradigm, task_type):\n",
    "    files = select_eeg_files_for_subject_by_paradigm(subject_id, paradigm, task_type)\n",
    "    epochs = load_and_concatenate_to_epochs(files, tmin=TMIN, tmax=TMAX, picks=MOTOR_CHANNELS)\n",
    "    epochs.filter(l_freq=L_FREQ, h_freq=H_FREQ, verbose=False) #Filter\n",
    "    return epochs\n",
    "\n",
    "\n",
    "def get_pipeline_scores_for_subject(subject_id, paradigm, task_type):\n",
    "\n",
    "    epochs = get_epochs_for_subject(subject_id, paradigm, task_type)\n",
    "    \n",
    "    # Extract data and labels\n",
    "    X = epochs.get_data()  # (n_trials, n_channels, n_times)\n",
    "    y = epochs.events[:, -1]  # Labels (2 or 3 for left/right)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('csp', CSP(n_components=N_COMPONENTS, reg=None, log=True)),\n",
    "        ('lda', LinearDiscriminantAnalysis())\n",
    "    ])\n",
    "    \n",
    "    # Cross-validation on training set\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=K_FOLDS)\n",
    "    \n",
    "    # Train on full training set and evaluate on test set\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    \n",
    "    return {\n",
    "        'cv_score': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_score': test_score\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "subject_ids = [f\"S{i:03d}\" for i in range(1, 110)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569461e5-f510-482a-aa5e-3b812c9ad035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline_on_experiment(task_paradigm, task_type):\n",
    "    \n",
    "    subject_results = []\n",
    "    LIMIT=109\n",
    "    \n",
    "    for i in tqdm(range(LIMIT)):\n",
    "        results = get_pipeline_scores_for_subject(subject_ids[i], task_paradigm, task_type)\n",
    "        subject_results.append(results)\n",
    "\n",
    "    \n",
    "    results_df = pd.DataFrame(subject_results)\n",
    "    return {\n",
    "        \"task_paradigm\" : task_paradigm,\n",
    "        \"task_type\" : task_type,\n",
    "        \"cv_score\" : float(results_df.mean()[\"cv_score\"]),\n",
    "        \"test_score\" : float(results_df.mean()[\"test_score\"])\n",
    "    }\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a05662-8658-4f39-a125-f1ede085d8d7",
   "metadata": {},
   "source": [
    "## Evaluate on all experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f474aa9c-a31b-4cf6-8676-680a5c4f6d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 109/109 [01:13<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 0: accuracy = 0.5928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 109/109 [01:15<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment 1: accuracy = 0.5703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██████▍                                                                                 | 8/109 [00:06<01:21,  1.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexperiment 1: accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp1[\u001b[33m'\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m experiments.append(exp1)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m exp2 = \u001b[43mevaluate_pipeline_on_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhands_feet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmotor_execution\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mexperiment 2: accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp2[\u001b[33m'\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m experiments.append(exp2)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mevaluate_pipeline_on_experiment\u001b[39m\u001b[34m(task_paradigm, task_type)\u001b[39m\n\u001b[32m      4\u001b[39m LIMIT=\u001b[32m109\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(LIMIT)):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     results = \u001b[43mget_pipeline_scores_for_subject\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_paradigm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     subject_results.append(results)\n\u001b[32m     11\u001b[39m results_df = pd.DataFrame(subject_results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mget_pipeline_scores_for_subject\u001b[39m\u001b[34m(subject_id, paradigm, task_type)\u001b[39m\n\u001b[32m     41\u001b[39m pipeline = Pipeline([\n\u001b[32m     42\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcsp\u001b[39m\u001b[33m'\u001b[39m, CSP(n_components=N_COMPONENTS, reg=\u001b[38;5;28;01mNone\u001b[39;00m, log=\u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[32m     43\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mlda\u001b[39m\u001b[33m'\u001b[39m, LinearDiscriminantAnalysis())\n\u001b[32m     44\u001b[39m ])\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Cross-validation on training set\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mK_FOLDS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Train on full training set and evaluate on test set\u001b[39;00m\n\u001b[32m     50\u001b[39m pipeline.fit(X_train, y_train)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:651\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    649\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:373\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    372\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:91\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     79\u001b[39m warning_filters = (\n\u001b[32m     80\u001b[39m     filters_func() \u001b[38;5;28;01mif\u001b[39;00m filters_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m warnings.filters\n\u001b[32m     81\u001b[39m )\n\u001b[32m     83\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     84\u001b[39m     (\n\u001b[32m     85\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     90\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:184\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m                 this_warning_filter_dict[special_key] = this_value.pattern\n\u001b[32m    182\u001b[39m         warnings.filterwarnings(**this_warning_filter_dict, append=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:833\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    831\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    832\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    836\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    837\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:613\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    607\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    608\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m     )\n\u001b[32m    612\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:547\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    541\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    542\u001b[39m     step_idx=step_idx,\n\u001b[32m    543\u001b[39m     step_params=routed_params[name],\n\u001b[32m    544\u001b[39m     all_params=raw_params,\n\u001b[32m    545\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    557\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    558\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/pipeline.py:1484\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1482\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1483\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1486\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1487\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1488\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/decoding/csp.py:322\u001b[39m, in \u001b[36mCSP.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit CSP to data, then transform it.\u001b[39;00m\n\u001b[32m    299\u001b[39m \n\u001b[32m    300\u001b[39m \u001b[33;03mFits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m \u001b[33;03m    and shape is ``(n_epochs, n_components, n_times)``.\u001b[39;00m\n\u001b[32m    320\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# use parent TransformerMixin method but with custom docstring\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/sklearn/base.py:910\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/decoding/csp.py:230\u001b[39m, in \u001b[36mCSP.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    226\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_params(y=y)\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Covariance estimation, GED/AJD\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# and evecs/evals sorting happen here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m pick_filters = \u001b[38;5;28mself\u001b[39m.filters_[: \u001b[38;5;28mself\u001b[39m.n_components]\n\u001b[32m    233\u001b[39m X = np.asarray([np.dot(pick_filters, epoch) \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m X])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/decoding/base.py:149\u001b[39m, in \u001b[36m_GEDTransformer.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    142\u001b[39m     X, y = \u001b[38;5;28mself\u001b[39m._check_data(\n\u001b[32m    143\u001b[39m         X,\n\u001b[32m    144\u001b[39m         y=y,\n\u001b[32m    145\u001b[39m         fit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    146\u001b[39m         return_y=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_ged_params()\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m covs, C_ref, info, rank, kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcov_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m covs = np.stack(covs)\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_covariances(covs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/decoding/_covs_ged.py:97\u001b[39m, in \u001b[36m_csp_estimate\u001b[39m\u001b[34m(X, y, reg, cov_method_params, cov_est, info, rank, norm_trace)\u001b[39m\n\u001b[32m     95\u001b[39m sample_weights = []\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ci, this_class \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes_):\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     cov, weight = \u001b[43mcov_estimator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis_class\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcov_kind\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclass=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthis_class\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mci\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcov_method_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_method_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m norm_trace:\n\u001b[32m    108\u001b[39m         cov /= np.trace(cov)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/decoding/_covs_ged.py:23\u001b[39m, in \u001b[36m_concat_cov\u001b[39m\u001b[34m(x_class, cov_kind, log_rank, reg, cov_method_params, info, rank)\u001b[39m\n\u001b[32m     20\u001b[39m _, n_channels, _ = x_class.shape\n\u001b[32m     22\u001b[39m x_class = x_class.transpose(\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m).reshape(n_channels, -\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m cov = \u001b[43m_regularized_covariance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_method_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcov_kind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_kind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_ch_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cov, n_channels\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-254>:12\u001b[39m, in \u001b[36m_regularized_covariance\u001b[39m\u001b[34m(data, reg, method_params, info, rank, log_ch_type, log_rank, cov_kind, on_few_samples, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/cov.py:2180\u001b[39m, in \u001b[36m_regularized_covariance\u001b[39m\u001b[34m(data, reg, method_params, info, rank, log_ch_type, log_rank, cov_kind, on_few_samples, verbose)\u001b[39m\n\u001b[32m   2178\u001b[39m picks_list = _picks_by_type(info)\n\u001b[32m   2179\u001b[39m scalings = _handle_default(\u001b[33m\"\u001b[39m\u001b[33mscalings_cov_rank\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2180\u001b[39m cov = \u001b[43m_compute_covariance_auto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2183\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2186\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstop_early\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpicks_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpicks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcov_kind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcov_kind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_ch_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_ch_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_few_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_few_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[reg][\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2196\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cov\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/cov.py:1276\u001b[39m, in \u001b[36m_compute_covariance_auto\u001b[39m\u001b[34m(data, method, info, method_params, cv, scalings, n_jobs, stop_early, picks_list, rank, cov_kind, log_ch_type, log_rank, on_few_samples)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;66;03m# rescale to improve numerical stability\u001b[39;00m\n\u001b[32m   1275\u001b[39m orig_rank = rank\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m rank = \u001b[43m_compute_rank_raw_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_few_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_few_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_verbose_safe_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _scaled_array(data.T, picks_list, scalings):\n\u001b[32m   1285\u001b[39m     C = np.dot(data.T, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-249>:10\u001b[39m, in \u001b[36m_compute_rank_raw_array\u001b[39m\u001b[34m(data, info, rank, scalings, log_ch_type, on_few_samples, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/cov.py:1247\u001b[39m, in \u001b[36m_compute_rank_raw_array\u001b[39m\u001b[34m(data, info, rank, scalings, log_ch_type, on_few_samples, verbose)\u001b[39m\n\u001b[32m   1240\u001b[39m \u001b[38;5;129m@verbose\u001b[39m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compute_rank_raw_array\u001b[39m(\n\u001b[32m   1242\u001b[39m     data, info, rank, scalings, *, log_ch_type=\u001b[38;5;28;01mNone\u001b[39;00m, on_few_samples=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1243\u001b[39m ):\n\u001b[32m   1244\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RawArray\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_rank(\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m         \u001b[43mRawArray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_verbose_safe_false\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1248\u001b[39m         rank,\n\u001b[32m   1249\u001b[39m         scalings,\n\u001b[32m   1250\u001b[39m         info,\n\u001b[32m   1251\u001b[39m         log_ch_type=log_ch_type,\n\u001b[32m   1252\u001b[39m         on_few_samples=on_few_samples,\n\u001b[32m   1253\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-289>:10\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, data, info, first_samp, copy, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/io/array/_array.py:73\u001b[39m, in \u001b[36mRawArray.__init__\u001b[39m\u001b[34m(self, data, info, first_samp, copy, verbose)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(info[\u001b[33m\"\u001b[39m\u001b[33mch_names\u001b[39m\u001b[33m\"\u001b[39m]) == info[\u001b[33m\"\u001b[39m\u001b[33mnchan\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minfo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     info = \u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mboth\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m orig_data:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/_fiff/meas_info.py:1002\u001b[39m, in \u001b[36mValidatedDict.copy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Copy the instance.\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Returns\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1000\u001b[39m \u001b[33;03m        The copied info.\u001b[39;00m\n\u001b[32m   1001\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/copy.py:143\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    141\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    145\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ft-total-perspective-vortex/.venv/lib/python3.12/site-packages/mne/_fiff/meas_info.py:1925\u001b[39m, in \u001b[36mInfo.__deepcopy__\u001b[39m\u001b[34m(self, memodict)\u001b[39m\n\u001b[32m   1923\u001b[39m         result[k] = hms\n\u001b[32m   1924\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1925\u001b[39m         result[k] = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemodict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m result._unlocked = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   1927\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/copy.py:151\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    149\u001b[39m reductor = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__reduce_ex__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reductor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     rv = \u001b[43mreductor\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    153\u001b[39m     reductor = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__reduce__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run 4 experiments - print each as it completes\n",
    "experiments = []\n",
    "\n",
    "exp0 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_execution')\n",
    "print(f\"experiment 0: accuracy = {exp0['test_score']:.4f}\")\n",
    "experiments.append(exp0)\n",
    "\n",
    "exp1 = evaluate_pipeline_on_experiment('left_right_hand', 'motor_imagery')\n",
    "print(f\"experiment 1: accuracy = {exp1['test_score']:.4f}\")\n",
    "experiments.append(exp1)\n",
    "\n",
    "exp2 = evaluate_pipeline_on_experiment('hands_feet', 'motor_execution')\n",
    "print(f\"experiment 2: accuracy = {exp2['test_score']:.4f}\")\n",
    "experiments.append(exp2)\n",
    "\n",
    "exp3 = evaluate_pipeline_on_experiment('hands_feet', 'motor_imagery')\n",
    "print(f\"experiment 3: accuracy = {exp3['test_score']:.4f}\")\n",
    "experiments.append(exp3)\n",
    "\n",
    "# Final mean\n",
    "mean_accuracy = sum(e['test_score'] for e in experiments) / 4\n",
    "print(f\"\\nMean accuracy of 4 experiments: {mean_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda61193-43be-41bc-98a6-7199b101b0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
